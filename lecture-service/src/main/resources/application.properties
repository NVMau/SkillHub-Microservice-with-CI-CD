spring.application.name=lecture-service
server.port=${LECTURE_SERVICE_PORT}

#Mongo config
spring.data.mongodb.host=mongodb_lecture
spring.data.mongodb.port=${MONGO_ALL_ON_SYS}
spring.data.mongodb.database=${MONGO_LECTURE_DATABASE}
spring.data.mongodb.username=${MONGO_ROOT_USERNAME}
spring.data.mongodb.password=${MONGO_ROOT_PASSWORD}
spring.data.mongodb.authentication-database=admin


#AWS config
cloud.aws.credentials.accessKey=${AWS_ACCESS_KEY}
cloud.aws.credentials.secretKey=${AWS_SECRET_KEY}
cloud.aws.region.static=${AWS_REGION}
cloud.aws.s3.bucket=${AWS_S3_BUCKET_LECTURE}

# Increase file upload size
spring.servlet.multipart.max-file-size=50MB
spring.servlet.multipart.max-request-size=50MB




# Kafka Producer Configuration
spring.kafka.bootstrap-servers=${KAFKA_BROKER_BOOTSTRAP_SERVER}
spring.kafka.template.default-topic=lectures-deleted
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=io.confluent.kafka.serializers.KafkaAvroSerializer
spring.kafka.producer.properties.schema.registry.url=${SCHEMA_REGISTRY_URL}

# Kafka Consumer Configuration
spring.kafka.consumer.group-id=lecture-service
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer
spring.kafka.consumer.properties.schema.registry.url=${SCHEMA_REGISTRY_URL}
spring.kafka.consumer.properties.specific.avro.reader=true



management.endpoints.web.exposure.include=*
management.metrics.distribution.percentiles-histogram.http.server.requests=true
management.observations.key-values.application=lecture-service
management.tracing.sampling.probability=1.0